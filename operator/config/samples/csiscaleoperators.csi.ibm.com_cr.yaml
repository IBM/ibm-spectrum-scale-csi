---
apiVersion: csi.ibm.com/v1
kind: "CSIScaleOperator"
metadata:
  name: "ibm-spectrum-scale-csi"
  namespace: "ibm-spectrum-scale-csi-driver"
  labels:
    app.kubernetes.io/name: ibm-spectrum-scale-csi-operator
    app.kubernetes.io/instance: ibm-spectrum-scale-csi-operator
    app.kubernetes.io/managed-by: ibm-spectrum-scale-csi-operator
    release: ibm-spectrum-scale-csi-operator
status: {}
spec:

# A passthrough option that distributes an imagePullSecrets array to the containers
# generated by the csi scale operator. Please refer to official k8s documentation for
# your environment for more details. https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
# ==================================================================================
#  imagePullSecrets:
#    - APullSecret
#    - AnotherOptional

# Below specifies the details of a IBM Storage Scale cluster configuration used by the
# plugin. It can have multiple values.
# ==================================================================================
  clusters:
    - id: "<Primary Cluster ID>"
      secrets: "secret1"
      secureSslMode: false
      primary:
        primaryFs: "< Primary Filesystem >"
#        primaryFset: "< Fileset in Primary Filesystem >"   # Optional - default:spectrum-scale-csi-volume-store
#        inodeLimit: "< inode limit for Primary Fileset >" # Optional
#        remoteCluster: "< Remote ClusterID >"            # Optional - This is only required if primaryFs is remote cluster's filesystem and this ID should have separate entry in Clusters map too.
#      cacert:  "< Name of CA cert configmap for GUI >"   # Optional
      restApi:
        - guiHost: "< IP/Hostname of a GUI node of primary cluster >"
#       - guiHost: "< IP/Hostname of another GUI node of primary cluster >" #Optional - Multiple GUI IPs/Hostnames can be provided like this, if the storage cluster has GUI installed on multiple nodes.
#
# In the case we have multiple clusters, specify their configuration below.
# ==================================================================================
#    - id: "< Cluster ID >"
#      secrets: "< Secret for Cluster >"
#      secureSslMode: false
#      restApi:
#      - guiHost: "< IP/Hostname of a GUI node of the cluster >"
#      - guiHost: "< IP/Hostname of another GUI node of the cluster >" #Optinal - Multiple GUI IPs/Hostnames can be provided like this, if the storage cluster has GUI installed on multiple nodes.
#      cacert:  "< Name of CA cert configmap for GUI >"   # Optional

# attacherNodeSelector specifies on which nodes we want to run attacher sidecar
# In below example attacher will run on nodes which have label as "scale=true"
# and "infranode=2". Can have multiple entries.
# ==================================================================================
  attacherNodeSelector:
    - key: "scale"
      value: "true"
#    - key: "infranode"
#      value: "2"

# provisionerNodeSelector specifies on which nodes we want to run provisioner
# sidecar. In below example provisioner will run on nodes which have label as
# "scale=true" and "infranode=1". Can have multiple entries.
# ==================================================================================
  provisionerNodeSelector:
    - key: "scale"
      value: "true"
#    - key: "infranode"
#      value: "1"

# snapshotterNodeSelector specifies on which nodes we want to run snapshotter
# sidecar. In below example snapshotter pod will run on nodes which have label as
# "scale=true" and "infranode=1". Can have multiple entries.
# ==================================================================================
  snapshotterNodeSelector:
    - key: "scale"
      value: "true"
#    - key: "infranode"
#      value: "1"

# resizerNodeSelector specifies on which nodes we want to run resizer
# sidecar. In below example resizer pod will run on nodes which have label as
# "scale=true" and "infranode=1". Can have multiple entries.
# ==================================================================================
  resizerNodeSelector:
    - key: "scale"
      value: "true"
#    - key: "infranode"
#      value: "1"

# pluginNodeSelector specifies nodes on which we want to run plugin daemoset
# In below example plugin daemonset will run on nodes which have label as
# "scale=true". Can have multiple entries.
# ==================================================================================
  pluginNodeSelector:
    - key: "scale"
      value: "true"

# In case K8s nodes name differs from IBM Storage Scale nodes name, we can provide
# node mapping using nodeMapping attribute. Can have multiple entries.
# ==================================================================================
#  nodeMapping:
#    - k8sNode: "< K8s Node Name >"
#      spectrumscaleNode: "< IBM Storage Scale Node Name >"
# In case K8s node name start with number then use following node mapping format.
#    - k8sNode: "K8sNodePrefix_< K8s Node Name >"
#      spectrumscaleNode: "< IBM Storage Scale Node Name >"

# Array of tolerations that will be distribued to CSI pods. Please refer to official
# k8s documentation for your environment for more details.
# https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
# ==================================================================================
#  tolerations:
#    - key: "key1"
#      operator: "Equal"
#      value: "value1"
#      effect: "NoExecute"
#      tolerationSeconds: 3600

# Kubelet root directory path, in case we don't want to use the default kubelet
# root directory path.
# ==================================================================================
#  kubeletRootDirPath: "/var/lib/kubelet"
